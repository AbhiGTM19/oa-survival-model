{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 1: Setup, Sync & Install ---\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# 1. Clean up old repo to force a fresh clone\n",
                "!rm -rf oa-survival-model\n",
                "\n",
                "# 2. Clone your repo\n",
                "from kaggle_secrets import UserSecretsClient\n",
                "user_secrets = UserSecretsClient()\n",
                "git_token = user_secrets.get_secret(\"GIT_TOKEN\")\n",
                "username = \"AbhiGTM19\"\n",
                "\n",
                "!git clone https://{username}:{git_token}@github.com/{username}/oa-survival-model.git\n",
                "\n",
                "# 3. Install Dependencies\n",
                "# We force install the specific versions that work\n",
                "%cd oa-survival-model\n",
                "!pip install -r requirements.txt\n",
                "!pip install torchsurv  # Ensure this is installed even if missing in requirements\n",
                "%cd ..\n",
                "\n",
                "# 4. Add source code to path\n",
                "sys.path.append('/kaggle/working/oa-survival-model/src')\n",
                "\n",
                "print(\"Environment Ready & Dependencies Installed.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 2: Build & Impute Data (New Pipeline) ---\n",
                "# This step generates the high-quality imputed dataset\n",
                "%cd oa-survival-model\n",
                "!python src/build_mega_cohort.py\n",
                "!python src/impute_biomarkers.py\n",
                "%cd ..\n",
                "\n",
                "print(\"âœ… Data Built & Imputed Successfully.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 3: Imports & Configuration ---\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision import transforms\n",
                "from sklearn.model_selection import train_test_split\n",
                "import torchsurv.loss\n",
                "from torch.cuda.amp import GradScaler, autocast # Mixed Precision\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "# Import your custom modules\n",
                "from model import WideAndDeepSurvivalModel, SemanticEncoder\n",
                "from dataset import TriModalDataset\n",
                "\n",
                "# Configuration\n",
                "if torch.cuda.is_available():\n",
                "    DEVICE = torch.device(\"cuda\")\n",
                "    GPU_COUNT = torch.cuda.device_count()\n",
                "    print(f\"Training on: {GPU_COUNT} x NVIDIA GPU(s)\")\n",
                "else:\n",
                "    DEVICE = torch.device(\"cpu\")\n",
                "    GPU_COUNT = 0\n",
                "    print(\"Training on: CPU\")\n",
                "\n",
                "# Paths\n",
                "# We use the newly generated IMPUTED dataset\n",
                "PARQUET_PATH = 'oa-survival-model/data/processed/OAI_mega_cohort_imputed.parquet'\n",
                "IMAGE_ROOT = '/kaggle/input/knee-osteoarthritis-dataset-with-severity' \n",
                "\n",
                "# Hyperparameters\n",
                "BATCH_SIZE = 32 * max(1, GPU_COUNT) \n",
                "EPOCHS = 20 # Survival model converges fast, 20 is usually enough\n",
                "LEARNING_RATE = 1e-4"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 4: Data Prep (Tri-Modal) ---\n",
                "\n",
                "# 1. Load Data\n",
                "df = pd.read_parquet(PARQUET_PATH)\n",
                "print(f\"Loaded Cohort: {len(df)} patients\")\n",
                "\n",
                "# 2. Preprocessing (One-Hot Encoding for Categoricals)\n",
                "# KL_Grade is categorical 0-4\n",
                "df = pd.get_dummies(df, columns=['KL_Grade'], drop_first=False) # Keep all for clarity or drop_first if preferred\n",
                "# Ensure expected columns exist (0.0 to 4.0)\n",
                "expected_kl = ['KL_Grade_0.0', 'KL_Grade_1.0', 'KL_Grade_2.0', 'KL_Grade_3.0', 'KL_Grade_4.0']\n",
                "for col in expected_kl:\n",
                "    if col not in df.columns:\n",
                "        df[col] = 0\n",
                "\n",
                "# Sex is already 0/1 from imputation script, but let's be safe\n",
                "if 'Sex_2' not in df.columns and 'Sex' in df.columns:\n",
                "    # If Sex is 0/1, we might treat it as is, or one-hot. \n",
                "    # The dataset.py expects 'Sex_2' (Female) if using one-hot, OR just 'Sex' if numeric.\n",
                "    # Let's check dataset.py logic. It uses 'Sex_2' in the list.\n",
                "    # We will create Sex_2 for compatibility.\n",
                "    df['Sex_2'] = df['Sex'] # Assuming 1=Female\n",
                "\n",
                "# 3. Split\n",
                "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
                "\n",
                "# 4. Transforms (Standard ResNet RGB for Survival Model)\n",
                "train_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(10),\n",
                "    transforms.Grayscale(num_output_channels=3), # Force 3 channels for ResNet\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "val_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.Grayscale(num_output_channels=3),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# 5. Datasets\n",
                "# mode='prod' tries to match IDs. If images missing, it blacks them out (safe).\n",
                "# mode='sandbox' picks random images. \n",
                "# USE 'sandbox' if your IDs don't match filenames yet.\n",
                "DATASET_MODE = 'sandbox' \n",
                "\n",
                "train_dataset = TriModalDataset(train_df, IMAGE_ROOT, transform=train_transform, mode=DATASET_MODE)\n",
                "val_dataset = TriModalDataset(val_df, IMAGE_ROOT, transform=val_transform, mode=DATASET_MODE)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 5: Tri-Modal Training Loop (Fixed Dimensions) ---\n",
                "\n",
                "# 1. Initialize Model (Corrected Input Dimensions)\n",
                "# wide_input_dim = 15 (Updated Feature Set)\n",
                "# bio_input_dim = 5   (Biomarkers)\n",
                "model = WideAndDeepSurvivalModel(wide_input_dim=15, bio_input_dim=5).to(DEVICE)\n",
                "\n",
                "if GPU_COUNT > 1:\n",
                "    model = nn.DataParallel(model)\n",
                "\n",
                "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
                "scaler = GradScaler() \n",
                "\n",
                "# 2. Robust Cox Loss Function\n",
                "if hasattr(torchsurv.loss, 'cox'):\n",
                "    base_cox = torchsurv.loss.cox\n",
                "    def safe_cox_loss(risk, events, times):\n",
                "        return base_cox(risk.float(), events.float(), times.float())\n",
                "    cox_loss_func = safe_cox_loss\n",
                "else:\n",
                "    # Fallback\n",
                "    def custom_cox_loss(risk, events, times):\n",
                "        risk = risk.float(); events = events.float(); times = times.float()\n",
                "        order = torch.argsort(times, descending=True)\n",
                "        risk = risk[order]\n",
                "        events = events[order]\n",
                "        log_cumsum = torch.logcumsumexp(risk, dim=0)\n",
                "        if events.sum() > 0:\n",
                "            return -torch.sum(events * (risk - log_cumsum)) / events.sum()\n",
                "        return torch.tensor(0.0, requires_grad=True, device=DEVICE)\n",
                "    cox_loss_func = custom_cox_loss\n",
                "\n",
                "# 3. Loop\n",
                "print(\"Starting Survival Training...\")\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    \n",
                "    # Unpack 5 Items: Image, Clin, Bio, Event, Time\n",
                "    for batch_idx, (images, clinical, bio, events, times) in enumerate(train_loader):\n",
                "        if events.sum() == 0: continue # Skip empty event batches\n",
                "\n",
                "        # Move to GPU\n",
                "        images = images.to(DEVICE)\n",
                "        clinical = clinical.to(DEVICE)\n",
                "        bio = bio.to(DEVICE)\n",
                "        events = events.to(DEVICE)\n",
                "        times = times.to(DEVICE)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        with autocast():\n",
                "            # Forward Pass (Tri-Modal)\n",
                "            risk_scores = model(images, clinical, bio).squeeze()\n",
                "            loss = cox_loss_func(risk_scores, events, times)\n",
                "        \n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        \n",
                "    print(f\"Epoch {epoch+1}/{EPOCHS} | Avg Loss: {total_loss/len(train_loader):.4f}\")\n",
                "\n",
                "# Save the Tri-Modal Model\n",
                "torch.save(model.module.state_dict() if GPU_COUNT > 1 else model.state_dict(), \"tri_modal_survival_model.pth\")\n",
                "print(\"Saved Tri-Modal Model.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 6: Evaluation ---\n",
                "from sksurv.metrics import concordance_index_censored\n",
                "import numpy as np\n",
                "\n",
                "print(\"Evaluating on Validation Set...\")\n",
                "model.eval()\n",
                "\n",
                "val_risk_scores = []\n",
                "val_events = []\n",
                "val_times = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for images, clinical, bio, events, times in val_loader:\n",
                "        images = images.to(DEVICE)\n",
                "        clinical = clinical.to(DEVICE)\n",
                "        bio = bio.to(DEVICE)\n",
                "        \n",
                "        # Forward\n",
                "        outputs = model(images, clinical, bio).squeeze()\n",
                "        \n",
                "        # Store\n",
                "        val_risk_scores.extend(outputs.cpu().numpy())\n",
                "        val_events.extend(events.numpy().astype(bool))\n",
                "        val_times.extend(times.numpy())\n",
                "\n",
                "c_index = concordance_index_censored(\n",
                "    np.array(val_events),\n",
                "    np.array(val_times),\n",
                "    np.array(val_risk_scores)\n",
                ")\n",
                "\n",
                "print(f\"Validation C-index: {c_index[0]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 7: Save Survival Model ---\n",
                "SAVE_PATH = \"tri_modal_survival_model.pth\"\n",
                "# Unwrap DataParallel if necessary\n",
                "state_dict = model.module.state_dict() if GPU_COUNT > 1 else model.state_dict()\n",
                "torch.save(state_dict, SAVE_PATH)\n",
                "print(f\"Saved: {SAVE_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 8: GenAI Setup ---\n",
                "from diffusers import UNet2DModel, DDPMScheduler\n",
                "from tqdm.auto import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "import torchvision.models as models\n",
                "from torch.utils.data import Dataset\n",
                "from PIL import Image\n",
                "import glob\n",
                "import gc\n",
                "import torch.nn.functional as F\n",
                "\n",
                "print(\"Generative AI Setup Complete.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# --- CELL 9: Production Generative Training (Multi-GPU T4) ---\n",
                "\n",
                "# --- 1. CONFIGURATION ---\n",
                "GEN_EPOCHS = 500   \n",
                "LR = 1e-4\n",
                "\n",
                "# Check Device & Multi-GPU\n",
                "if torch.cuda.is_available():\n",
                "    DEVICE = torch.device(\"cuda\")\n",
                "    GPU_COUNT = torch.cuda.device_count()\n",
                "    print(f\"Training on: {GPU_COUNT} x NVIDIA GPU(s)\")\n",
                "    BATCH_SIZE = 32 * GPU_COUNT # 64 total\n",
                "else:\n",
                "    DEVICE = torch.device(\"cpu\")\n",
                "    GPU_COUNT = 0\n",
                "    BATCH_SIZE = 16\n",
                "    print(\"Training on: CPU (Not Recommended)\")\n",
                "\n",
                "if not os.path.exists(\"checkpoints\"):\n",
                "    os.makedirs(\"checkpoints\")\n",
                "\n",
                "# --- 2. ROBUST CLASSES ---\n",
                "class SemanticEncoder(nn.Module):\n",
                "    def __init__(self, latent_dim=256): \n",
                "        super().__init__()\n",
                "        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
                "        original_first = resnet.conv1\n",
                "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
                "        with torch.no_grad():\n",
                "            resnet.conv1.weight[:] = original_first.weight.sum(dim=1, keepdim=True) / 3.0\n",
                "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
                "        self.projection = nn.Linear(512, latent_dim)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = self.features(x).view(x.size(0), -1)\n",
                "        z = self.projection(x)\n",
                "        return z\n",
                "\n",
                "class GrayscaleDataset(Dataset):\n",
                "    def __init__(self, image_dir, transform=None):\n",
                "        self.transform = transform\n",
                "        self.image_paths = glob.glob(f\"{image_dir}/**/*.png\", recursive=True) + \\\n",
                "                           glob.glob(f\"{image_dir}/**/*.jpg\", recursive=True)\n",
                "        print(f\"Generative Dataset: {len(self.image_paths)} images.\")\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        # Random sampling for robustness\n",
                "        path = np.random.choice(self.image_paths)\n",
                "        try:\n",
                "            img = Image.open(path).convert('L')\n",
                "            if self.transform:\n",
                "                img = self.transform(img)\n",
                "            return img\n",
                "        except:\n",
                "            return torch.zeros(1, 64, 64)\n",
                "\n",
                "# --- 3. INITIALIZE ---\n",
                "print(\"Initializing Models...\")\n",
                "unet = UNet2DModel(\n",
                "    sample_size=64, in_channels=1, out_channels=1, layers_per_block=2,\n",
                "    block_out_channels=(64, 128, 128, 256),\n",
                "    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"AttnDownBlock2D\", \"DownBlock2D\"),\n",
                "    up_block_types=(\"UpBlock2D\", \"AttnUpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"),\n",
                "    class_embed_type=\"identity\"\n",
                ").to(DEVICE)\n",
                "\n",
                "encoder = SemanticEncoder(latent_dim=256).to(DEVICE)\n",
                "\n",
                "if GPU_COUNT > 1:\n",
                "    print(f\"Activating DataParallel on {GPU_COUNT} GPUs...\")\n",
                "    unet = nn.DataParallel(unet)\n",
                "    encoder = nn.DataParallel(encoder)\n",
                "\n",
                "scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
                "optimizer = torch.optim.Adam(list(unet.parameters()) + list(encoder.parameters()), lr=LR)\n",
                "scaler = GradScaler()\n",
                "\n",
                "# --- 4. LOAD DATA ---\n",
                "IMAGE_ROOT = '/kaggle/input/knee-osteoarthritis-dataset-with-severity' \n",
                "\n",
                "gen_transform = transforms.Compose([\n",
                "    transforms.Resize((64, 64)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.5], [0.5])\n",
                "])\n",
                "\n",
                "dataset = GrayscaleDataset(IMAGE_ROOT, transform=gen_transform)\n",
                "\n",
                "# OPTIMIZED: Set num_workers to 4 (Max for Kaggle CPU) to avoid freezing\n",
                "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4*GPU_COUNT)\n",
                "\n",
                "# --- 5. TRAIN ---\n",
                "print(f\"Starting Production Training ({GEN_EPOCHS} Epochs)...\")\n",
                "\n",
                "for epoch in range(GEN_EPOCHS):\n",
                "    unet.train()\n",
                "    encoder.train()\n",
                "    total_loss = 0\n",
                "    \n",
                "    progress = tqdm(loader, desc=f\"Epoch {epoch+1}/{GEN_EPOCHS}\", leave=False)\n",
                "    \n",
                "    for images in progress:\n",
                "        images = images.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        with autocast():\n",
                "            z = encoder(images)\n",
                "            noise = torch.randn_like(images)\n",
                "            t = torch.randint(0, scheduler.config.num_train_timesteps, (images.shape[0],), device=DEVICE).long()\n",
                "            noisy_images = scheduler.add_noise(images, noise, t)\n",
                "            \n",
                "            # return_dict=False handles DataParallel output correctly\n",
                "            noise_pred = unet(noisy_images, t, class_labels=z, return_dict=False)[0]\n",
                "            \n",
                "            loss = F.mse_loss(noise_pred, noise)\n",
                "        \n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        progress.set_postfix({\"loss\": loss.item()})\n",
                "        \n",
                "    avg_loss = total_loss / len(loader)\n",
                "    print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f}\")\n",
                "\n",
                "    # Checkpoint every 50 epochs\n",
                "    if (epoch + 1) % 50 == 0:\n",
                "        unet_save = unet.module if isinstance(unet, nn.DataParallel) else unet\n",
                "        enc_save = encoder.module if isinstance(encoder, nn.DataParallel) else encoder\n",
                "        \n",
                "        torch.save(unet_save.state_dict(), f\"checkpoints/unet_epoch_{epoch+1}.pth\")\n",
                "        torch.save(enc_save.state_dict(), f\"checkpoints/encoder_epoch_{epoch+1}.pth\")\n",
                "        print(f\"--> Saved Checkpoint {epoch+1}\")\n",
                "\n",
                "# Final Save\n",
                "unet_save = unet.module if isinstance(unet, nn.DataParallel) else unet\n",
                "enc_save = encoder.module if isinstance(encoder, nn.DataParallel) else encoder\n",
                "torch.save(unet_save.state_dict(), \"diffusion_unet.pth\")\n",
                "torch.save(enc_save.state_dict(), \"semantic_encoder.pth\")\n",
                "print(\"Training Complete.\")"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [
                {
                    "datasetId": 1257880,
                    "sourceId": 2097406,
                    "sourceType": "datasetVersion"
                },
                {
                    "datasetId": 8893735,
                    "sourceId": 13955145,
                    "sourceType": "datasetVersion"
                }
            ],
            "dockerImageVersionId": 31192,
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}